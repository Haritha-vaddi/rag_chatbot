# rag_chatbot

# Project Overview

This project is a Retrieval-Augmented Generation (RAG) prototype that assists UK bank compliance analysts in answering COREP regulatory reporting questions using official regulatory documents.

## The System

- Accepts a natural-language query
- Retrieves relevant PRA Rulebook / COREP instructions from a PDF
- Uses Gemini LLM to generate structured, schema-aligned output
- Produces audit-ready JSON suitable for regulatory reporting workflows

## üéØ Problem Statement

UK banks subject to the PRA Rulebook must submit COREP regulatory returns that accurately reflect capital, risk exposures, and prudential metrics.

Preparing these returns is:

- Labour-intensive
- Error-prone
- Requires interpreting dense and frequently updated regulatory text

This prototype demonstrates how an LLM-assisted reporting assistant can:

- Retrieve relevant regulatory rules
- Populate structured COREP fields
- Provide traceable rule references and audit logs

## üß† Solution Approach (RAG Architecture)

The system follows an end-to-end RAG pipeline:

```
User Query
   ‚Üì
Semantic Retrieval (ChromaDB)
   ‚Üì
Relevant Regulatory Context
   ‚Üì
Gemini LLM
   ‚Üì
Structured JSON Output
```

## üß© Key Components

### 1Ô∏è‚É£ Document Ingestion

- Loads PRA / COREP regulatory PDF documents
- Each page is converted into structured text

### 2Ô∏è‚É£ Chunking

- Large documents are split into overlapping chunks
- Ensures context preservation and efficient retrieval

### 3Ô∏è‚É£ Embeddings

- Text chunks are converted into vector embeddings using `all-MiniLM-L6-v2`

### 4Ô∏è‚É£ Vector Database

- Embeddings are stored in ChromaDB
- Enables fast semantic search

### 5Ô∏è‚É£ Retrieval

- Top-K relevant chunks are retrieved for each query

### 6Ô∏è‚É£ LLM Generation

- Gemini (gemini-2.5-flash) generates responses
- Output strictly follows a predefined JSON schema
